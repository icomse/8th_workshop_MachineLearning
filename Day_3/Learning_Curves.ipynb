{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0CxQv7Ept0b"
      },
      "source": [
        "# Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "x5fUBW9QoPAL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.optimize as op\n",
        "import scipy.io as sio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8dLOHeFtdQg"
      },
      "source": [
        "We will perform some Bias and Variance Testing using the data below. It relates the flowrate of a water leak to the changes in water level in a tank.\n",
        "\n",
        "First, we will access the data in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgsLDeddp3n6"
      },
      "outputs": [],
      "source": [
        "mat_contents = sio.loadmat(\"LC.mat\")\n",
        "\n",
        "#print(mat_contents)\n",
        "\n",
        "#Assign values to matrices\n",
        "\n",
        "#Training set\n",
        "X = mat_contents['X']\n",
        "y = mat_contents['y'].flatten()\n",
        "\n",
        "#Validation set\n",
        "X_val = mat_contents['Xval']\n",
        "y_val = mat_contents['yval'].flatten()\n",
        "\n",
        "#Test set\n",
        "X_test = mat_contents['Xtest']\n",
        "y_test = mat_contents['ytest'].flatten()\n",
        "\n",
        "print(len(y), len(y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ps1vcWavpKX"
      },
      "source": [
        "It is always a good idea to plot the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp_1_LUowdxO"
      },
      "outputs": [],
      "source": [
        "#Plot the training data\n",
        "\n",
        "plt.scatter(X,y)\n",
        "plt.xlabel('Change in water level (L)')\n",
        "plt.ylabel('Water flowing out (L)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAiLeSEJ1NyF"
      },
      "source": [
        "A good place to start is doing linear regression. Code the cost function for a regularized linear regression below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mYHW3m3L4Hsn"
      },
      "outputs": [],
      "source": [
        "#Regularized Linear Regression\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkb94sku4DoU"
      },
      "source": [
        "Now code a function for the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HPOkZNmqKnuN"
      },
      "outputs": [],
      "source": [
        "def Gradient(theta, X,y, l):\n",
        "  '''Gradient of cost function\n",
        "    Inputs:\n",
        "  X = features\n",
        "  y = training data\n",
        "  theta = parameters\n",
        "  l = regularization parameter\n",
        "  Output:\n",
        "  grad = gradient of cost function\n",
        "  '''\n",
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgnAQa44Xjd"
      },
      "source": [
        "With our cost and gradient functions, let's use optimization tools to find the best parameters for a simple line on our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4-UA7XDJcp-9"
      },
      "outputs": [],
      "source": [
        "#Optimize\n",
        "m = len(y)\n",
        "ones = np.ones(m)\n",
        "\n",
        "#X_new is our feature matrix with the added column of ones.\n",
        "X_new = np.vstack((ones,X.T)).T\n",
        "l = 0\n",
        "initial_theta = np.array([0,0])\n",
        "Result = op.minimize(fun = cost, x0=initial_theta, args = (X_new,y,l), method='TNC', jac = Gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0LDGLwC4gND"
      },
      "source": [
        "Plot the hypothesis along with the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRNAcOmafeq_"
      },
      "outputs": [],
      "source": [
        "x_line = np.linspace(np.min(X),np.max(X),50)\n",
        "\n",
        "theta_opt = Result.x\n",
        "y_line = theta_opt[0] + theta_opt[1]*x_line\n",
        "\n",
        "plt.plot(x_line,y_line)\n",
        "plt.scatter(X,y)\n",
        "plt.xlabel('Change in water level (L)')\n",
        "plt.ylabel('Water flowing out (L)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKECDNrf42Y_"
      },
      "source": [
        "Clearly, a simple line is not good enough for the data. What model should we use? To start answering that question, we need to use Learning Curves. Finish the function below which takes in the testing and validation sets along with regularization parameters and returns the error as a function of the number of data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iMQYy8uTgN-a"
      },
      "outputs": [],
      "source": [
        "#Learning Curves\n",
        "\n",
        "def learningcurve(X,y,X_val,y_val,l):\n",
        "  '''\n",
        "  Function to calculate training and validation error\n",
        "  Inputs:\n",
        "  X=training set features (assumes already has columns of 1)\n",
        "  y=training set data\n",
        "  X_val = validation features (assumes already has columns of 1)\n",
        "  y_val = validation data\n",
        "  l = regularization parameter\n",
        "\n",
        "  Output:\n",
        "  [error_train, error_val] = array with training and validation errors as a function of the number of data points\n",
        "  '''\n",
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlYfgIiV5TPD"
      },
      "source": [
        "With our Learning Curves function coded it up, we can see the results for our system. What kind of issues do the learning curves reveal for this model and data?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Ozg4zZtG3j"
      },
      "outputs": [],
      "source": [
        "#Test learning curve function\n",
        "\n",
        "m_val = len(y_val)\n",
        "ones = np.ones(m_val)\n",
        "\n",
        "#X_new is our feature matrix with the added column of ones.\n",
        "X_val_new = np.vstack((ones,X_val.T)).T\n",
        "\n",
        "\n",
        "error_train,error_val = learningcurve(X_new,y,X_val_new,y_val,0)\n",
        "\n",
        "plt.plot(error_train)\n",
        "plt.plot(error_val)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctrvzhEk5vQK"
      },
      "source": [
        "Clearly a simple line is not enough. Adding polynomial features is something we could try, but that means we need to alter our feature matrix accordingly. What is the function below doing? Add the appropriate comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aqOQXoVDuTPB"
      },
      "outputs": [],
      "source": [
        "#Say we want to try a polynomial of degree 8.\n",
        "\n",
        "#Need to build the appropriate feature matrices.\n",
        "def build_feat(X,p):\n",
        "  X_feat = X.copy()\n",
        "  for i in range(2,p+1):\n",
        "    X_feat = np.vstack((X_feat.T,X_feat[:,1]**i)).T\n",
        "  return X_feat\n",
        "\n",
        "X_feat = build_feat(X_new,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGCrBHaT7qpQ"
      },
      "source": [
        "Adding polynomial features also means we are changing the scale of the features. Standardization in this case becomes necessary if we want to use optimization algorithms. Complete the function below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M6HTbvw1RWo"
      },
      "outputs": [],
      "source": [
        "#Now need to normalize (standardize) the data\n",
        "\n",
        "## Write function to standardize data\n",
        "\n",
        "def featureNormalize(X):\n",
        "  '''Function that takes as input an array of data and outputs a standardized dataset\n",
        "  '''\n",
        "  X_norm = X.copy()\n",
        "  ###BEGIN SOLUTION\n",
        "\n",
        "  ###END SOLUTION\n",
        "  return X_norm\n",
        "\n",
        "norm = featureNormalize(X_feat)\n",
        "\n",
        "print(norm, np.mean(norm,0),np.std(norm,0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bRISRqO9Wza"
      },
      "source": [
        "Now use the cell below to find the optimal thetas for our new hypothesis (set regularization to 0). Plot the data with your optimal hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOtK-RFJ4KDo"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkRjlGBE_ha3"
      },
      "source": [
        "With our data and model plotted, plot the learning curves for the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydVoOBt9-_Cm"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZJHsjMYBESt"
      },
      "source": [
        "Use a regularization value of 1 and determine the optimal parameters. Plot the data along with the final hypothesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWKWpgBTDmyl"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaqZLeNlBUgm"
      },
      "source": [
        "Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyxXju15Qssv"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNBP_tYZCtUS"
      },
      "source": [
        "Repeat the process (finding optimal thetas and plotting the learning curves) but using a regularization value of 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5qMcKWbNy4m"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3-tNllAN20R"
      },
      "outputs": [],
      "source": [
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAaqS5m1Dbyt"
      },
      "source": [
        "How should we pick lambda? Using the concepts that we have discussed in lecture (learning curves), approximately what value of lambda should we choose?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8kBGD6KQ_WU"
      },
      "outputs": [],
      "source": [
        "#How to pick lambda?\n",
        "\n",
        "l_vec = np.array([0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10])\n",
        "\n",
        "###BEGIN SOLUTION\n",
        "\n",
        "###END SOLUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "cme6ybl1eZd4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 [3.7]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}